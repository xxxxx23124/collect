import torch
import torch.nn.functional as F
from collections import defaultdict
from torch.utils.tensorboard import SummaryWriter

from experiment.DDPM.Model.UNet import TimeAwareCondConv2d

class ExpertMonitor:
    def __init__(self, model, log_dir="runs/ddpm_experts"):
        self.hooks = []
        # ç”¨ list æ¥å­˜å‚¨å¤šæ¬¡ forward çš„ç»“æœ
        self.batch_buffer = defaultdict(list)
        self.layer_names = []
        self.writer = SummaryWriter(log_dir)
        self._register_hooks(model)
        print(f"ğŸ‘€ ç´¯ç§¯å¼ç›‘æ§å™¨å·²å¯åŠ¨ï¼æ—¥å¿—å°†ä¿å­˜åˆ°: {log_dir}")

    def _register_hooks(self, model):
        """
        è‡ªåŠ¨éå†æ¨¡å‹ï¼Œæ‰¾åˆ°æ‰€æœ‰çš„ TimeAwareCondConv2dã€‚
        """
        # éå†æ‰€æœ‰æ¨¡å—ï¼Œå¯»æ‰¾ç›®æ ‡å±‚
        for name, module in model.named_modules():
            # æˆ‘ä»¬åªå…³å¿ƒ TimeAwareCondConv2d
            if isinstance(module, TimeAwareCondConv2d):
                # æ³¨å†Œ Hook
                hook = module.router.register_forward_hook(
                    self._get_hook_fn(name)
                )
                self.hooks.append(hook)
                self.layer_names.append(name)
        print(f"å…±ç›‘æ§äº† {len(self.hooks)} ä¸ª TimeAwareCondConv2d å±‚")

    def _get_hook_fn(self, layer_name):
        """
        ç”Ÿæˆé—­åŒ…é’©å­å‡½æ•°ï¼Œä¸ºäº†è®°ä½æ˜¯å“ªä¸€å±‚çš„åå­—ã€‚
        """

        def hook(module, input, output):
            # output: (MiniBatch, num_experts) -> Logits
            # å¦‚æœæ¨¡å‹ä¸åœ¨è®­ç»ƒæ¨¡å¼ï¼Œç›´æ¥æ— è§†
            if not module.training:
                return
            with torch.no_grad():
                probs = F.softmax(output, dim=1)
                # è®¡ç®—å½“å‰ Mini-Batch çš„å¹³å‡ä½¿ç”¨ç‡
                # è¿™é‡Œå¾—åˆ° [num_experts] çš„å‘é‡
                avg_usage = probs.mean(dim=0).detach().cpu()

                # Append åˆ°ç¼“å­˜åˆ—è¡¨ä¸­
                self.batch_buffer[layer_name].append(avg_usage)

        return hook

    def log_and_reset(self, global_step):
        """
        è¿™ä¸ªå‡½æ•°è¦åœ¨ optimizer.step() ä¹‹åè°ƒç”¨ã€‚
        å®ƒä¼šç»“ç®—è¿‡å»å‡ æ¬¡ forward çš„æ€»è´¦ï¼Œå†™å…¥ TensorBoardï¼Œç„¶åæ¸…ç©ºç¼“å­˜ã€‚
        """
        for layer_name, usage_list in self.batch_buffer.items():
            if not usage_list:
                continue

            # usage_list æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œé‡Œé¢æœ‰ accumulation_steps ä¸ª tensor
            # æ¯”å¦‚ 10 ä¸ª [4] çš„ tensor
            # æˆ‘ä»¬å°†å®ƒä»¬ stack èµ·æ¥å˜æˆ [10, 4]ï¼Œç„¶åå¯¹ dim=0 æ±‚å¹³å‡
            # è¿™æ ·å¾—åˆ°çš„å°±æ˜¯æ•´ä¸ª Effective Batch çš„å¹³å‡ä¸“å®¶ä½¿ç”¨ç‡
            accumulated_usage = torch.stack(usage_list).mean(dim=0)

            # 1. è®°å½•æ¯ä¸ªä¸“å®¶çš„æ›²çº¿
            for i, u in enumerate(accumulated_usage):
                self.writer.add_scalar(f"Expert_Usage/{layer_name}/Exp_{i}", u, global_step)

            # 2. è®°å½•ç†µ (åæ˜ è´Ÿè½½å‡è¡¡åº¦)
            entropy = -torch.sum(accumulated_usage * torch.log(accumulated_usage + 1e-9))
            self.writer.add_scalar(f"Expert_Entropy/{layer_name}", entropy, global_step)

        # ã€å…³é”®ã€‘æ¸…ç©ºç¼“å­˜ï¼Œè¿æ¥ä¸‹ä¸€ä¸ª Accumulation Cycle
        self.batch_buffer.clear()

    def close(self):
        for h in self.hooks:
            h.remove()
        self.writer.close()